<html>
  <head>
    <title>Valkyrie Savage Project 7</title>
  </head>
  <body>
    <h1>Mosaic stitching</h1>
    <h3>Valkyrie Savage</h3>
    <h2>introduction</h2>
    The big idea of this project is taking a collection of photos captured from the same viewpoint and stitching them together into a larger photo mosaic.  In part 1, this is accomplished by matching user-selected points in both images.  In part 2, points and correspondences are algorithmically automatically determined.  The images are made to match by determining a homography (8DOF warp) between these correspondence points using least-squares error minimization.<br/>
    <h2>rectification</h2>
    A smaller step on the way to mosaic images, image rectification is taking an image with a known rectangular object in it, selecting its corners, and warping that object to be a rectangle.  For whatever reason, Matlab's least squares solver doesn't work very hard on these rectangles: when the transformation is performed with just 3 points, they make a beautiful right angle, but when a 4th point is added it's total madness.<br/>

    <table>
      <tr><td width=33%><b>Source image</b></td><td width=33%><b>Rectified image - 3 corners</b></td><td><b>Rectified images - 4 corners</b></td></tr>
      <tr><td><img src="samples/april-shadow.png" width=100%></td><td><img src="3cornerpuppies.jpg" width=100%/></td><td><img src="4cornerpuppies.jpg" width=100%/></td></tr>
      <tr><td><img src="samples/yesond.jpg" width=100%></td><td><img src="3cornersoda.jpg" width=100%/></td><td><img src="4cornersoda.jpg" width=100%/></td></tr>
      <tr><td><img src="samples/shiry.jpg" width=100%></td><td><img src="3cornershiry.jpg" width=100%/></td><td><img src="4cornershiry.jpg" width=100%/></td></tr>
    </table>

    <h2>mosaics</h2>
    The real meat and potatoes of this assignment, of course, is the full-on image warping.  All of my image warps used around 15 correspondence points between each pair of neighboring pictures (and all are composed of 3 images).  The way I "blended" the images was by feathering all their edges prior to warping and summing based on alpha values to get the final artifact.<br/>
    
    <table>
      <tr><td width=20%><b>Title/story</b></td><td width=40%><b>Source images</b></td><td width=40%><b>Mosaic</b></td></tr>
      <tr><td>These images of the Berkeley rose garden come from just around the corner of my house.  Amusingly, Google seems to have implemented one of the bells and whistles from part 2 and very helpfully offered an "auto-awesome" photo of these images as a pre-stitched panorama.  Thanks, Google!</td><td><img src="samples/rose1-1.jpg" width=30%><img src="samples/rose1-2.jpg" width=30%/><img src="samples/rose1-3.jpg" width=30%/></td><td><img src="pano-rosegarden.jpg" width=100%/></td></tr>
      <tr><td>These images, taken on Oahu when I was there recently for a conference, surprised me a little when they worked.  I knew that we had a panorama assignment coming up, so I snapped several photos, but this was before I knew about the hard constraint of taking photos from the same spot.  Still, they worked out well (aside from the exposures...).</td><td><img src="samples/hawaii-0-left.jpg" width=30%><img src="samples/hawaii-1-leftcenter.jpg" width=30%/><img src="samples/hawaii-2-rightcenter.jpg" width=30%/></td><td><img src="pano-hawaii.jpg" width=100%/></td></tr>
      <tr><td>These images, of Munich international airport, were clipped from a video I apparently randomly decided to take of the airport when I flew through in July.  I stood in one spot in front of the terminal and spun around, and to build this mosaic I just screenshotted a few frames nearby each other.  The billboard top doesn't match up extremely well (not rectified), I think because I had a challenging time finding any keypoints along that part of the image to force alignment on.</td><td><img src="samples/munich-0.png" width=30%><img src="samples/munich-1.png" width=30%/><img src="samples/munich-2.png" width=30%/></td><td><img src="pano-munich.jpg" width=100%/></td></tr>
    </table>

    <h2>introduction: part 2</h2>
    But, really, how annoying is it to click a bunch of places?  Aren't computers smart enough to figure out correspondences for themselves?  None of these datasets is particularly challenging (they are all pretty clean).  So... algorithms to the rescue!  I, for one, welcome our new robot overlords.<br/>
    <h2>point generation</h2>
    Points are generated automatically using a lovely Harris corner finder developed by our own Alyosha Efros.  This algorithm reacts to things that look like "corners"; i.e., things that have strongish gradients in both x and y directions.<br/>
    <img src="puppies-harris.jpg" /><br/>
    However, there are a LOT of points there.  To be a bit clever about it, we want to lessen the number of points but keep the distribution pretty nice.  Enter Adaptive Non-Maximal Suppression!<br/>
    <img src="puppies-ANMS.jpg"/><br/>
    The general idea of ANMS is to use the "strength" of each corner to hide weaker corners within a radius (iteratively).  We just have to determine what suppression radius is good and gets us the number of corners we want.<br/>
    <h2>point matching</h2>
    The "Russian Granny" algorithm presented in class states that if a point doesn't have a clear match, far better than all the rest, then it should remain unmatched.  This is related to a young Russian who should not get married unless one of their choices is clearly better than the rest.<br/>The functional part of this is that 40x40 patches around each control point are extracted from the image, then they are normalized (subtract mean value of patch, divide by variance of patch), and re-sized to 8x8 pixels.<br/>
    <table>
      <tr><td width=50%><img src="russiangranny.png"></td><td width=50%><img src="russiangranny1.png"></td></tr>
    </table>
    <br/>
    The descriptors above were matched by the Russian Granny.
    <h2>homography identification</h2>
    Still, though, some grannies are fallible.  They can give bad advice!  Using points that contain bad advice to generate a homography can wind up with some very sketchy homographies.  Therefore we do one more thing before we follow the processing pipeline above: we RANSAC that $#!+.<br/>
    The RANSAC algorithm takes a collection of matched points and calculates a homography for every set of 4 points in that collection.  For each homography, it warps the points to see how they do.  With each warping, we count the number of inliers vs. outliers in our point set (an inlier is defined as being within 3 pixels of where its match is after warping).  We then choose the homography with the most inliers.<br/>
    From here, we can run the algorithm as normal from above.  My images were so similar to the ones from the hand-done output that I don't include them here (although they can be rendered using my code).<br/>
    <h2>bells & whistles</h2>
    I collected my panorama data for this assignment using my Android phone.  As Alyosha mentioned in class, Google does this nice thing for you:<br/>
    <img src="google-auto-pano.png" width=100%/><br/>
    It discovered that I had taken photos "over a wide area" and helpfully stitched them together into a panorama for me.  I can tell you, this was rather demotivational from the perspective of finishing the first assignment.<br/>
    However, this is not too difficult to accomplish.  Given a collection of images, they can be run pair-wise through the automatic steps above and panoramas can pop out!  The two thresholds that I use for my rejection are if the Russian Granny declares that <10 points match between the two images and if RANSAC says that <50% of the points in its best homography are inliers.<br/>
    <img src="discovered-pano.jpg" width=100%/><br/>
    An automatically discovered panorama.
  </body>
</html>
